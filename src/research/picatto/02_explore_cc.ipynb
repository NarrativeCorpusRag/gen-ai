{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b825f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/picatto/ascii/gen-ai/.pixi/envs/basic-research/lib/python3.12/site-packages/surt/handyurl.py:37: SyntaxWarning: invalid escape sequence '\\+'\n",
      "  _RE_HAS_PROTOCOL = re.compile(b\"^([a-zA-Z][a-zA-Z0-9\\+\\-\\.]*):\")\n",
      "/home/picatto/ascii/gen-ai/.pixi/envs/basic-research/lib/python3.12/site-packages/surt/handyurl.py:100: SyntaxWarning: invalid escape sequence '\\?'\n",
      "  ^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?\n",
      "/home/picatto/ascii/gen-ai/.pixi/envs/basic-research/lib/python3.12/site-packages/surt/URLRegexTransformer.py:31: SyntaxWarning: invalid escape sequence '\\('\n",
      "  re.compile(b\"^(.*/)(\\((?:[a-z]\\([0-9a-z]{24}\\))+\\)/)([^\\?]+\\.aspx.*)$\", re.I),\n",
      "/home/picatto/ascii/gen-ai/.pixi/envs/basic-research/lib/python3.12/site-packages/surt/GoogleURLCanonicalizer.py:168: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  input, safe=b'''!\"$&'()*+,-./:;<=>?@[\\]^_`{|}~''').encode(\n",
      "/home/picatto/ascii/gen-ai/.pixi/envs/basic-research/lib/python3.12/site-packages/surt/IAURLCanonicalizer.py:127: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  _RE_WWWDIGITS = re.compile(b'www\\d*\\.')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import polars as pl\n",
    "import botocore\n",
    "import tarfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "from fastwarc import ArchiveIterator\n",
    "from fastwarc.stream_io import GZipStream\n",
    "from resiliparse.extract.html2text import extract_plain_text\n",
    "from resiliparse.parse.lang import detect_fast\n",
    "from resiliparse.parse.html import HTMLTree\n",
    "from fastwarc.warc import is_http\n",
    "from surt import surt\n",
    "import tldextract\n",
    "import idna\n",
    "import re\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from resiliparse.parse.encoding import detect_encoding, bytes_to_str\n",
    "\n",
    "client = boto3.client('s3', \n",
    "                      aws_access_key_id=os.getenv('ASCII_AWS_ACCESS_KEY_ID'),\n",
    "        aws_secret_access_key=os.getenv('ASCII_AWS_SECRET_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawls = [\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251115220136-05256.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251115234907-05257.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116014712-05258.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116034034-05259.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116054722-05260.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116072531-05261.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116085944-05262.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116103419-05263.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116120640-05264.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116134805-05265.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116152516-05266.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116170848-05267.warc.gz',\n",
    "'crawl-data/CC-NEWS/2025/11/CC-NEWS-20251116190217-05268.warc.gz']\n",
    "key = 'crawl-data/CC-NEWS/index.html'\n",
    "response = client.get_object(Bucket='commoncrawl', Key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cba6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_gz = 'crawl-data/CC-NEWS/2025/11/warc.paths.gz'\n",
    "\n",
    "response = client.get_object(Bucket='commoncrawl', Key=key_gz)\n",
    "    \n",
    "gzipped_body_bytes = response['Body'].read()\n",
    "    \n",
    "decompressed_bytes = gzip.decompress(gzipped_body_bytes)\n",
    "content_str = decompressed_bytes.decode('utf-8')\n",
    "    \n",
    "print(content_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_pattern = re.compile(r\"^(?:www\\.)?\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\Z\")\n",
    "host_part_pattern = re.compile(\n",
    "    r\"^[a-z0-9]([a-z0-9_-]{0,61}[a-z0-9])?\\Z\", re.IGNORECASE | re.ASCII\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246518f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surt_host(url):  # noqa: C901\n",
    "    extracted = tldextract.extract(url, include_psl_private_domains=True)\n",
    "    registered_domain = extracted.top_domain_under_public_suffix\n",
    "\n",
    "    if registered_domain == \"\":\n",
    "        registered_domain = f\"{extracted.subdomain}.{extracted.domain}\"\n",
    "        if registered_domain == \"\":\n",
    "            try:\n",
    "                # Fallback to urlparse if tldextract fails\n",
    "                host = urlparse(url).hostname\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse URL {url}: {e}\")\n",
    "                return None\n",
    "            if not host:\n",
    "                return None\n",
    "        else:\n",
    "            host = registered_domain\n",
    "    else:\n",
    "        host = registered_domain\n",
    "\n",
    "    host = host.strip().lower()\n",
    "    if len(host) < 1 or len(host) > 253:\n",
    "        return None\n",
    "    if ip_pattern.match(host):\n",
    "        return None\n",
    "    parts = host.split(\".\")\n",
    "    if parts[-1] == \"\":\n",
    "        # trailing dot is allowed, strip it\n",
    "        parts = parts[0:-1]\n",
    "    if len(parts) <= 1:\n",
    "        # do not accept single-word hosts, must be at least `domain.tld'\n",
    "        return None\n",
    "    if len(parts) > 2 and parts[0] == \"www\":\n",
    "        # strip leading 'www' to reduce number of \"duplicate\" hosts,\n",
    "        # but leave at least 2 trailing parts (www.com is a valid domain)\n",
    "        parts = parts[1:]\n",
    "    for i, part in enumerate(parts):\n",
    "        if len(part) > 63:\n",
    "            return None\n",
    "        if not host_part_pattern.match(part):\n",
    "            try:\n",
    "                idn = idna.encode(part).decode(\"ascii\")\n",
    "            except (\n",
    "                idna.IDNAError,\n",
    "                idna.core.InvalidCodepoint,\n",
    "                UnicodeError,\n",
    "                IndexError,\n",
    "                Exception,\n",
    "            ):\n",
    "                print(\"Invalid host name: {}\".format(url))\n",
    "                return None\n",
    "\n",
    "            # TODO: idna verifies the resulting string for length restrictions or invalid chars,\n",
    "            #       maybe no further verification is required:\n",
    "            if host_part_pattern.match(idn):\n",
    "                parts[i] = idn\n",
    "            else:\n",
    "                print(\"Invalid host name: {}\".format(url))\n",
    "                return None\n",
    "    parts.reverse()\n",
    "    return \".\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c8e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_response = client.get_object(Bucket='commoncrawl', Key=key)\n",
    "s3_stream = s3_response['Body']\n",
    "stream = GZipStream(s3_stream)\n",
    "from fastwarc.warc import ArchiveIterator, WarcRecordType\n",
    "tmp = []\n",
    "for key in crawls:\n",
    "    for record in ArchiveIterator(stream, record_types=WarcRecordType.response, func_filter=is_http):\n",
    "        uri = record.headers.get('WARC-Target-URI')\n",
    "        body_bytes = record.reader.read()\n",
    "        html = bytes_to_str(body_bytes, detect_encoding(body_bytes))\n",
    "        text = extract_plain_text(html)\n",
    "        http_date =record.http_date \n",
    "        http_last_modified = record.http_last_modified \n",
    "        http_charset= record.http_charset \n",
    "        surt_uri = surt(uri)\n",
    "        host = get_surt_host(uri)\n",
    "        r = detect_fast(text, n_results=3)\n",
    "        langs = []\n",
    "        confs = []\n",
    "        for i in range(len(r)):\n",
    "            langs.append(r[i][0])\n",
    "            confs.append(r[i][1])\n",
    "        tmp.append({\n",
    "            'uri': uri,\n",
    "            'tree': html,\n",
    "            'text': text,\n",
    "            'main_lang': r[0][0], \n",
    "            'langs': langs, \n",
    "            'confs': confs,\n",
    "            'http_date': http_date,\n",
    "            'http_last_modified': http_last_modified,\n",
    "            'http_charset': http_charset,\n",
    "            'surt_uri': surt_uri,\n",
    "            'host': host})\n",
    "    pl.from_dicts(tmp).with_columns(\n",
    "        pl.lit(key.split('/')[-1]).alias('path'),\n",
    "    pl.lit(key.split('/')[-2]).alias('year'),\n",
    "    pl.lit(key.split('/')[-3]).alias('month'),\n",
    "    ).write_parquet('/data/raid5/data/picatto/ascii/news/', partition_by=['year','month', 'path', 'main_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a720127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixi.toml',\n",
       " '.gitignore',\n",
       " '.gitattributes',\n",
       " '.git',\n",
       " 'src',\n",
       " 'docs',\n",
       " '.pixi',\n",
       " 'pixi.lock',\n",
       " 'data']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../../../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ffd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pl.from_dicts(tmp)\n",
    "tmp_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
